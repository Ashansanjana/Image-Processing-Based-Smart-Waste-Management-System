{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e68dd4c",
   "metadata": {},
   "source": [
    "# Garbage Classification â€” Full notebook with image preprocessing (step-by-step)\n",
    "\n",
    "This notebook:\n",
    "- Loads the garbage classification dataset (from folder structure),\n",
    "- Applies an **image preprocessing pipeline** (histogram equalization, blur, Sobel edges) using a `preprocessing_function` for `ImageDataGenerator`,\n",
    "- Trains two models (DenseNet121 and ResNet101V2) with transfer learning,\n",
    "- Evaluates and visualizes results (confusion matrix, classification report),\n",
    "- Includes visualization of **original vs enhanced** images.\n",
    "\n",
    "**Note:** Adjust `path` if your dataset location is different (example: Google Drive or Kaggle dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578daf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D , MaxPooling2D , Dense , Flatten , Dropout , GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential , Model\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet101V2\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# optimizer\n",
    "from tensorflow.keras.optimizers import Adam, AdamW\n",
    "\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c507e2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Parameters & dataset path\n",
    "# Change this path if your dataset is elsewhere (e.g., Google Drive or local)\n",
    "path = '/kaggle/input/garbage-classification/garbage_classification'  # <-- keep or update\n",
    "img_size = 128\n",
    "batch_size = 32\n",
    "random_state = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43490050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build dataframe of image filepaths and labels\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for root, dirs, files in os.walk(path):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "            filepath = os.path.join(root, file)\n",
    "            filepaths.append(filepath)\n",
    "            label = os.path.basename(root)\n",
    "            labels.append(label)\n",
    "\n",
    "data_df = pd.DataFrame({'filepath': filepaths, 'original_label': labels})\n",
    "print('Total images found:', len(data_df))\n",
    "data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26c28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Unify labels (example: unify various glass subfolders into 'glass')\n",
    "def unify_glass_labels(label):\n",
    "    if 'glass' in label.lower():\n",
    "        return 'glass'\n",
    "    return label\n",
    "\n",
    "data_df['unified_label'] = data_df['original_label'].apply(unify_glass_labels)\n",
    "data_df.drop(columns=['original_label'], inplace=True)\n",
    "\n",
    "print('Class distribution:')\n",
    "display(data_df['unified_label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a46c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Train / Test split (stratified)\n",
    "train_df, test_df = train_test_split(\n",
    "    data_df,\n",
    "    test_size=0.2,\n",
    "    stratify=data_df['unified_label'],\n",
    "    random_state=random_state\n",
    ")\n",
    "\n",
    "print('Train samples:', len(train_df))\n",
    "print('Test samples :', len(test_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370a47a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Preprocessing function\n",
    "# This function is compatible with ImageDataGenerator.preprocessing_function.\n",
    "# Keras calls the preprocessing_function after rescale (so input here will be float32 in [0,1]).\n",
    "# We convert back to 0-255 before applying cv2 operations, then return a float array in [0,1].\n",
    "\n",
    "def enhance_preprocessing(img):\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    # img: float32 in [0,1], shape (H, W, 3), color order: RGB\n",
    "    # Convert to uint8 [0,255]\n",
    "    arr = (img * 255).astype('uint8')\n",
    "    # Convert RGB -> Grayscale\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_RGB2GRAY)\n",
    "    # Histogram equalization\n",
    "    equalized = cv2.equalizeHist(gray)\n",
    "    # Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(equalized, (3, 3), 0)\n",
    "    # Sobel edge detection\n",
    "    sobelx = cv2.Sobel(blurred, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    sobely = cv2.Sobel(blurred, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "    sobel = np.clip(sobel, 0, 255).astype('uint8')\n",
    "    # Stack back to 3 channels (RGB-like)\n",
    "    final = np.stack([sobel, sobel, sobel], axis=-1)\n",
    "    # Convert to float [0,1]\n",
    "    final = final.astype('float32') / 255.0\n",
    "    return final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e296335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Create ImageDataGenerators (with augmentation for training)\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=enhance_preprocessing  # apply our enhancement\n",
    ")\n",
    "\n",
    "test_gen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    preprocessing_function=enhance_preprocessing  # apply same preprocessing for evaluation\n",
    ")\n",
    "\n",
    "train_data = train_gen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='unified_label',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_data = test_gen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='unified_label',\n",
    "    target_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848d62b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Class indices & labels\n",
    "class_indices = train_data.class_indices\n",
    "print('Class indices (label -> index):')\n",
    "print(class_indices)\n",
    "\n",
    "# Build index -> label mapping for predictions later\n",
    "index_to_label = {v: k for k, v in class_indices.items()}\n",
    "classes = [index_to_label[i] for i in range(len(index_to_label))]\n",
    "print('\\nClasses (in model index order):', classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d37b6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Visualize: Original vs Enhanced\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Pick a sample image from test_df\n",
    "sample_fp = test_df['filepath'].iloc[0]\n",
    "print('Sample filepath:', sample_fp)\n",
    "\n",
    "orig = img_to_array(load_img(sample_fp, target_size=(img_size, img_size))) / 255.0\n",
    "enh = enhance_preprocessing(orig)\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(10,5))\n",
    "axes[0].imshow(orig)\n",
    "axes[0].set_title('Original (rescaled)')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(enh)\n",
    "axes[1].set_title('Enhanced (preprocessing_function)')\n",
    "axes[1].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693d4c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Train DenseNet121 (transfer learning)\n",
    "num_classes = len(class_indices)\n",
    "\n",
    "base_model = DenseNet121(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_DenseNet121 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "optimizer = AdamW(learning_rate=1e-4)\n",
    "model_DenseNet121.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model_DenseNet121.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c970e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Fit DenseNet121\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "earlystop = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy')\n",
    "checkpoint_path = 'dense121_best.h5'\n",
    "mc = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "history_dense = model_DenseNet121.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystop, mc]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f10b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Evaluate DenseNet121\n",
    "loss, accuracy = model_DenseNet121.evaluate(test_data)\n",
    "print(f'DenseNet121 -> Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predictions\n",
    "preds = model_DenseNet121.predict(test_data, verbose=1)\n",
    "y_pred_idx = np.argmax(preds, axis=1)\n",
    "y_pred_labels = [index_to_label[i] for i in y_pred_idx]\n",
    "y_true_labels = test_df['unified_label'].values\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(10,8))\n",
    "cm = confusion_matrix(y_true_labels, y_pred_labels, labels=classes)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('DenseNet121 - Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_true_labels, y_pred_labels, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8968c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Train ResNet101V2 (transfer learning)\n",
    "base_model = ResNet101V2(input_shape=(img_size, img_size, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = True\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model_ResNet101V2 = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "optimizer = AdamW(learning_rate=1e-4)\n",
    "model_ResNet101V2.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "model_ResNet101V2.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639722e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Fit ResNet101V2\n",
    "checkpoint_path_r = 'resnet101v2_best.h5'\n",
    "mc_r = ModelCheckpoint(checkpoint_path_r, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "earlystop_r = EarlyStopping(patience=5, restore_best_weights=True, monitor='val_accuracy')\n",
    "\n",
    "history_resnet = model_ResNet101V2.fit(\n",
    "    train_data,\n",
    "    validation_data=test_data,\n",
    "    epochs=epochs,\n",
    "    callbacks=[earlystop_r, mc_r]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ba64ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15) Evaluate ResNet101V2\n",
    "loss_r, accuracy_r = model_ResNet101V2.evaluate(test_data)\n",
    "print(f'ResNet101V2 -> Loss: {loss_r:.4f}, Accuracy: {accuracy_r:.4f}')\n",
    "\n",
    "# Predictions\n",
    "preds_r = model_ResNet101V2.predict(test_data, verbose=1)\n",
    "y_pred_idx_r = np.argmax(preds_r, axis=1)\n",
    "y_pred_labels_r = [index_to_label[i] for i in y_pred_idx_r]\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "cm_r = confusion_matrix(y_true_labels, y_pred_labels_r, labels=classes)\n",
    "sns.heatmap(cm_r, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "plt.title('ResNet101V2 - Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "print('\\nClassification Report (ResNet101V2):')\n",
    "print(classification_report(y_true_labels, y_pred_labels_r, target_names=classes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f9f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16) Plot training history (DenseNet121 vs validation)\n",
    "def plot_history(h, title='Model'):\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(h.history['accuracy'], label='train_acc')\n",
    "    plt.plot(h.history['val_accuracy'], label='val_acc')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_dense, title='DenseNet121 Accuracy')\n",
    "plot_history(history_resnet, title='ResNet101V2 Accuracy')\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
